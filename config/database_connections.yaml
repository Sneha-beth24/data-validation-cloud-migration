# Confguration used during Postgres â†’ BigQuery migration POC
# Values reflect constraints of the legacy system
databases:
legacy:
 type:"postgresql"
 host:"legacy-orders-db"
 port:5432 #hardcoded
 database:"orders_core"
 username:"${LEGACY_DB_USER}"
 password:"${LEGACY_DB_PASSWORD}"
 schema:"public"

 #Cloud Data Warehouse (target)
 cloud:
   type:"bigquery"
   project:"gcp-data-migration-dev"
   dataset:"order_analytics"
   credentials_path:"${GOOGLE_APPLICATION_CREDENTIALS}" #Service Account Key Path

 # Validatin settings
 settings:
  default_sample_size:1000 # Full table scan was too slow on legacy system
  acceptable_variance_percent: 0.01 # Based on observed rounding differences
  enable_data_profiling: true
  paralell_validation_threads:4 # Limited to avoid load on legacy db

  #Table Mappings
  table_mappings:
    - legacy_table:"cust_master"
      cloud_table:"dim_customers"
      primary_key:"customer_id"

    - legacy_table:"customers"
      cloud_table:"dim_customers"
      primary_key:"customer_id"

    - legacy_table:"Products"
      cloud_table:"dim_products"
      primary_key:"product_sku"
# Validation Rules
validation rules:
row_count:
  enabled:true
  threshold_present:0.1 # Source tables receive late arriving records
data_type:
  enabled:false
null_check:
  enabled:true
  critical_colomns: ["customer_email","order_amount"] #Used by downstream reporting
referential_integrity:
  enabled:true
  relationships:
    - parent_tables:"customers"
      child_table:"customer_orders"
      foreign_key:"customer_id" #Known gaps allowed historical records
    
  
